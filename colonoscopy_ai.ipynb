{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "version": "3.7.3-final"
    },
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "kernelspec": {
      "name": "python37464bitmyenvcondaab690425d1734e90bce0cf01b923e56c",
      "display_name": "Python 3.7.4 64-bit ('my_env': conda)"
    },
    "colab": {
      "name": "colonoscopy_ai.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miahong/Colonoscopy-AI/blob/master/colonoscopy_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gusGBZKbgJnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data exploration and data proprocessing\n",
        "import shutil\n",
        "import time\n",
        "import copy\n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils, datasets, models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6-krrrKgJnV",
        "colab_type": "code",
        "colab": {},
        "outputId": "816a91c0-e545-4136-a636-e3d58ef11f9c"
      },
      "source": [
        "# get both ungrouped AO and Non-AO image paths and check the total number of images\n",
        "AO_folder_path = \"/home/hongzhuoqiao/Colonoscopy-AI/data/model_data/AO/*\"\n",
        "NonAO_folder_path = \"/home/hongzhuoqiao/Colonoscopy-AI/data/model_data/Non-AO/*\"\n",
        "AO_files = glob.glob(AO_folder_path)\n",
        "NonAO_files = glob.glob(NonAO_folder_path)\n",
        "\n",
        "# AO image original path\n",
        "AO_img_path_list =[]\n",
        "for file in AO_files:\n",
        "    filename = os.path.basename(file)\n",
        "    AO_img_path_list.append(file)\n",
        "\n",
        "# Non AO image original path\n",
        "NonAO_img_path_list =[]\n",
        "for file in NonAO_files:\n",
        "    filename = os.path.basename(file)\n",
        "    NonAO_img_path_list.append(file)\n",
        "\n",
        "# Read and Store Each Images and shapes\n",
        "# AO image and shape\n",
        "AO_img_list =[]\n",
        "AO_img_shape_list =[]\n",
        "for path in AO_img_path_list[0:1]:\n",
        "    image = cv2.imread(path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    AO_img_list.append(image)\n",
        "    AO_img_shape_list.append(image.shape)\n",
        " \n",
        "# Non-AO image and shape\n",
        "NonAO_img_list =[]\n",
        "NonAO_img_shape_list =[]\n",
        "for path in NonAO_img_path_list[0:1]:\n",
        "    image = cv2.imread(path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    NonAO_img_list.append(image)\n",
        "    NonAO_img_shape_list.append(image.shape)\n",
        "\n",
        "# check unique shape size\n",
        "# AO unique shape\n",
        "AO_unique_shape_list =[]\n",
        "for s in AO_img_shape_list:\n",
        "    if s not in AO_unique_shape_list:\n",
        "        AO_unique_shape_list.append(s)\n",
        "\n",
        "NonAO_unique_shape_list =[]\n",
        "for s in NonAO_img_shape_list:\n",
        "    if s not in NonAO_unique_shape_list:\n",
        "        NonAO_unique_shape_list.append(s)\n",
        "\n",
        "AO_count = len(AO_img_path_list)\n",
        "NonAO_count = len(NonAO_img_path_list)\n",
        "total_count = AO_count + NonAO_count\n",
        "print (\"AO images have shape: {}\".format(AO_unique_shape_list))\n",
        "print (\"Non AO images have shape: {}\".format(NonAO_unique_shape_list))\n",
        "print (\"Overall, {} AO images, {} Non AO images, totally {} images.\".format(AO_count, NonAO_count, total_count))\n",
        "print (\"potential train count: {} \".format(int(total_count/10*8)+1))\n",
        "# plt.imshow(NonAO_img_list[0])\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AO images have shape: [(480, 736, 3)]\n",
            "Non AO images have shape: [(480, 720, 3)]\n",
            "Overall, 6559 AO images, 6663 Non AO images, totally 13222 images.\n",
            "potential train count: 10578 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub5a7JoLgJng",
        "colab_type": "code",
        "colab": {},
        "outputId": "64e36190-5932-4d1f-f19f-289e4b253467"
      },
      "source": [
        "# Data_loader for modeling\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKDER =4\n",
        "# Build transforms\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.RandomSizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "# Build the datasets\n",
        "model_dataset = datasets.ImageFolder(root='data/model_data', transform=data_transform)\n",
        "len(model_dataset)\n",
        "\n",
        "# Split the dataset into train valid and test dataset\n",
        "train_count = int(total_count/10*8) +1 \n",
        "valid_count = int((total_count - train_count)/2)\n",
        "test_count = int((total_count - train_count)/2)\n",
        "print('train, valid, test split count:{} {} {} '.format(train_count, valid_count, test_count))\n",
        "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(model_dataset, [train_count, valid_count, test_count])\n",
        "\n",
        "# Build Dataloader for three datasets, same dataloader for three datasets\n",
        "train_dataset_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKDER)\n",
        "valid_dataset_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKDER)\n",
        "test_dataset_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKDER)\n",
        "print (\"Dataloader have been built.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train, valid, test split count:10578 1322 1322 \n",
            "Dataloader have been built.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuuKCs96gJnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build train model with pretrain model\n",
        "LEARNING_RATE = 0.001\n",
        "MOMENTUM = 0.9\n",
        "STEP_SIZE = 7\n",
        "GAMMA = 0.1\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_ft = models.resnet18(pretrained=True)\n",
        "num_features = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_features, 2)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=LEARNING_RATE, momentum = MOMENTUM)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size = STEP_SIZE, gamma=GAMMA)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8FHxOYmgJnn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training model function\n",
        "# TODO: change the function to adjust the current dataloader \n",
        "# reference to https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html#training-the-model\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        #TODO: change here\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJKczotTgJnq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# N_EPOCHS = 25\n",
        "# model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=N_EPOCHS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvTIzjeOgJnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}